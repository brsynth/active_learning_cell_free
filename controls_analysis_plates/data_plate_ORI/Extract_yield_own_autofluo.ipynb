{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The aim of this file is to extract yield values from the TECAN and map it to the correct file\n",
    "import numpy as np\n",
    "import csv\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I'm extracting TECAN into a dictionnary (for starters)\n",
    "\n",
    "plate_name = \"ORI\"\n",
    "result_name = \"tecan_results\"\n",
    "\n",
    "# plate_name = \"plate_AL_1b\"\n",
    "# result_name = \"plate_AL_1b_raw\"\n",
    "\n",
    "CV = 30\n",
    "folder_result = \"raw_data\"\n",
    "\n",
    "localisation = \"{}/{}.csv\".format(folder_result, result_name)\n",
    "data_source = \"{}/{}_concentrations_reconstituted.csv\".format(folder_result, plate_name)\n",
    "export_place = \"{}/{}_yield_and_std.csv\".format(folder_result, plate_name)\n",
    "all_together_place = \"{}/{}_everything.csv\".format(folder_result, plate_name)\n",
    "draw_mean = \"{}/{}_draw_mean.csv\".format(folder_result, plate_name)\n",
    "draw_std =  \"{}/{}_draw_std.csv\".format(folder_result, plate_name)\n",
    "draw_ratio =  \"{}/{}_draw_ratio.csv\".format(folder_result, plate_name)\n",
    "outliers =  \"{}/{}_outliers.csv\".format(folder_result, plate_name)\n",
    "comments_file = \"{}/{}_comments.txt\".format(folder_result, plate_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_current_data = np.genfromtxt(data_source, delimiter=',', skip_header  = 1, dtype = \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A6\n",
      "A12\n",
      "A18\n",
      "OrderedDict([('nad', '0.099'), ('folinic_acid', '0.034'), ('DNA', '50'), ('coa', '0.026'), ('RBS', '10'), ('peg', '2'), ('nucleo_mix', '0.75'), ('spermidin', '0.3'), ('pga', '15'), ('aa', '0.75'), ('trna', '0.02'), ('mg_gluta', '1.2'), ('hepes', '50'), ('camp', '0.375'), ('K_gluta', '20'), ('promoter', '10'), ('name', 'P3')])\n"
     ]
    }
   ],
   "source": [
    "wells_information = {}\n",
    "\n",
    "with open(data_source) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if row[\"name\"] == \"\":\n",
    "            pass\n",
    "        if row[\"name\"] == \"P3\":\n",
    "            print(row)\n",
    "            wells_information[row[\"name\"]] = row\n",
    "        else:\n",
    "            wells_information[row[\"name\"]] = row\n",
    "            if row[\"DNA\"] == \"0\":\n",
    "                print(row[\"name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def present_in_array(new_sample, array):\n",
    "    present = False\n",
    "    new_sample = np.reshape(np.array(new_sample), (1,16))\n",
    "    for i in range(array.shape[0]):\n",
    "        if np.array_equiv(array[i,:],new_sample):\n",
    "            present = True\n",
    "            break\n",
    "    \n",
    "            \n",
    "    return(present, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting control and plate info separately information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DNA row is 3\n",
      "Empty DNA row (from row) is 3\n",
      "Reference row (from row) is 4\n",
      "P3 is 0\n",
      "P3 is 0\n"
     ]
    }
   ],
   "source": [
    "control_array = None\n",
    "plate_array = None\n",
    "control_max_array = None\n",
    "\n",
    "for well, row in wells_information.items():\n",
    "    this_sample_conc = [row[\"nad\"],\n",
    "                        row[\"folinic_acid\"], \n",
    "                        row[\"DNA\"], \n",
    "                        row[\"coa\"], \n",
    "                        row[\"RBS\"], \n",
    "                        row[\"peg\"], \n",
    "                        row[\"nucleo_mix\"],\n",
    "                        row[\"spermidin\"],\n",
    "                        row[\"pga\"],\n",
    "                        row[\"aa\"],\n",
    "                        row[\"trna\"],\n",
    "                        row[\"mg_gluta\"],\n",
    "                        row[\"hepes\"],\n",
    "                        row[\"camp\"],\n",
    "                        row[\"K_gluta\"],\n",
    "                        row[\"promoter\"]\n",
    "                         ]\n",
    "    if well.startswith(\"A\"):        \n",
    "        if control_array is None:\n",
    "            this_sample_conc.extend([well, '', ''])\n",
    "            this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "            control_array = this_sample_conc \n",
    "        else:\n",
    "            # already present in the array. \n",
    "            # Either file up a new line or...\n",
    "            present, i = present_in_array(this_sample_conc, control_array[:, 0:16])\n",
    "    #         present, i = present_in_array(this_sample_conc[:, 0:16], array_with_wells[:, 0:16])\n",
    "            if not present:    \n",
    "    #             if well == 'M21':\n",
    "    #                 print(i)\n",
    "                if well == 'A6':\n",
    "                    print(\"Empty DNA row is {}\".format(i))\n",
    "                if float(row[\"DNA\"]) == 0:\n",
    "                    print(\"Empty DNA row (from row) is {}\".format(i))\n",
    "                if well == 'M6':\n",
    "                    print(\"Reference row is {}\".format(i))\n",
    "                if float(row[\"K_gluta\"]) == 40 and float(row[\"DNA\"]) != 0:\n",
    "                    print(\"Reference row (from row) is {}\".format(i))\n",
    "                this_sample_conc.extend([well, '', ''])\n",
    "                this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "                control_array = np.concatenate((control_array, this_sample_conc), axis = 0)\n",
    "            else:\n",
    "                if control_array[i,17] == '':\n",
    "                    control_array[i,17] = well\n",
    "                elif control_array[i,18] == '':\n",
    "                    control_array[i,18] = well\n",
    "                else:\n",
    "                    # print(\"{}, {}, {}\".format(well, row, array_with_wells[i,:]))\n",
    "                    print(row[\"name\"])\n",
    "                    print(\"this makes sense, it's the max\")\n",
    "    elif well.startswith(\"P\"): \n",
    "        if control_max_array is None:\n",
    "            this_sample_conc.extend([well, '', ''])\n",
    "            this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "            control_max_array = this_sample_conc \n",
    "        else:\n",
    "            # already present in the array. \n",
    "            # Either file up a new line or...\n",
    "            present, i = present_in_array(this_sample_conc, control_max_array[:, 0:16])\n",
    "    #         present, i = present_in_array(this_sample_conc[:, 0:16], array_with_wells[:, 0:16])\n",
    "            if well == 'P3':\n",
    "                print(\"P3 is {}\".format(i))\n",
    "            if not present: \n",
    "                this_sample_conc.extend([well, '', '']) \n",
    "                if well == 'P3':\n",
    "                    print(\"P3 is {}\".format(i))\n",
    "                this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "                control_max_array = np.concatenate((control_max_array, this_sample_conc), axis = 0)\n",
    "            else:\n",
    "                if control_max_array[i,17] == '':\n",
    "                    control_max_array[i,17] = well\n",
    "                elif control_max_array[i,18] == '':\n",
    "                    control_max_array[i,18] = well\n",
    "                else:\n",
    "                    # print(\"{}, {}, {}\".format(well, row, array_with_wells[i,:]))\n",
    "                    print(row[\"name\"])\n",
    "                    print(\"this makes sense, it's the max\")\n",
    "    else:\n",
    "        if plate_array is None:\n",
    "            this_sample_conc.extend([well, '', ''])\n",
    "            this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "            plate_array = this_sample_conc\n",
    "        else:\n",
    "            # already present in the array. \n",
    "            # Either file up a new line or...\n",
    "            present, i = present_in_array(this_sample_conc, plate_array[:, 0:16])\n",
    "    #         present, i = present_in_array(this_sample_conc[:, 0:16], array_with_wells[:, 0:16])\n",
    "            if not present:    \n",
    "                if well == 'G3':\n",
    "                    print(\"G3 is {}\".format(i))\n",
    "                if well == 'M6':\n",
    "                    print(\"M6 is {}\".format(i))\n",
    "                if well == 'M18':\n",
    "                    print(\"M18 is {}\".format(i))\n",
    "#                 if well == 'C8':\n",
    "#                     print(i)\n",
    "                this_sample_conc.extend([well, '', ''])\n",
    "                this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "                plate_array = np.concatenate((plate_array, this_sample_conc), axis = 0)\n",
    "            else:\n",
    "                if plate_array[i,17] == '':\n",
    "                    plate_array[i,17] = well\n",
    "                elif plate_array[i,18] == '':\n",
    "                    plate_array[i,18] = well\n",
    "                else:\n",
    "                    print(\"{} is already present and it a duplciate of well {}\".format(row[\"name\"], plate_array[i,16]))\n",
    "                    this_sample_conc.extend([well, '', ''])\n",
    "                    this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "                    plate_array = np.concatenate((this_sample_conc, plate_array), axis = 0)\n",
    "                    # print(row)\n",
    "                    # print(\"this makes sense, it's the max\")\n",
    "# print(plate_array.shape)\n",
    "# print(plate_array[1:15, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.033' '0.0068' '50' '0.026' '10' '2' '0.15' '0.1' '3' '0.15' '0.02'\n",
      "  '0.4' '50' '0.075' '4' '10' 'A2' 'A8' 'A14']\n",
      " ['0.165' '0.0068' '50' '0.026' '10' '2' '0.15' '0.1' '9' '0.15' '0.02'\n",
      "  '0.4' '50' '0.375' '12' '10' 'A3' 'A9' 'A15']\n",
      " ['0.099' '0.0204' '50' '0.078' '10' '2' '0.15' '0.5' '3' '0.45' '0.1'\n",
      "  '1.2' '50' '0.225' '4' '10' 'A4' 'A10' 'A16']\n",
      " ['0.033' '0.0204' '50' '0.078' '10' '2' '0.15' '0.5' '9' '0.45' '0.06'\n",
      "  '2' '50' '0.225' '12' '10' 'A5' 'A11' 'A17']\n",
      " ['0.33' '0.068' '0' '0.26' '10' '2' '1.5' '1' '30' '1.5' '0.2' '4' '50'\n",
      "  '0.75' '40' '10' 'A6' 'A12' 'A18']\n",
      " ['0.33' '0.068' '50' '0.26' '10' '2' '1.5' '1' '30' '1.5' '0.2' '4' '50'\n",
      "  '0.75' '40' '10' 'A7' 'A13' 'A19']]\n",
      "['0.33' '0.068' '0' '0.26' '10' '2' '1.5' '1' '30' '1.5' '0.2' '4' '50'\n",
      " '0.75' '40' '10' 'A6' 'A12' 'A18']\n",
      "['0.33' '0.068' '50' '0.26' '10' '2' '1.5' '1' '30' '1.5' '0.2' '4' '50'\n",
      " '0.75' '40' '10' 'A7' 'A13' 'A19']\n",
      "['0.33' '0.068' '0' '0.26' '10' '2' '1.5' '1' '30' '1.5' '0.2' '4' '50'\n",
      " '0.75' '40' '10' 'A6' 'A12' 'A18']\n",
      "['0.33' '0.068' '50' '0.26' '10' '2' '1.5' '1' '30' '1.5' '0.2' '4' '50'\n",
      " '0.75' '40' '10' 'A7' 'A13' 'A19']\n"
     ]
    }
   ],
   "source": [
    "print(control_array)\n",
    "if control_array is None:\n",
    "    whole_array = plate_array\n",
    "else:\n",
    "    print(control_array[4,])\n",
    "    print(control_array[5,])\n",
    "    try:\n",
    "        whole_array = np.concatenate((control_array, plate_array, control_max_array), axis = 0)\n",
    "    except ValueError:\n",
    "        whole_array = np.concatenate((control_array, control_max_array), axis = 0)\n",
    "    print(whole_array[4,])\n",
    "    print(whole_array[5,])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 19)\n"
     ]
    }
   ],
   "source": [
    "print(whole_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing named wells with their values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_yield_dictionnary = {}\n",
    "\n",
    "with open(localisation) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        name_yield_dictionnary[row[\"name\"]] = row[\"Time_5\"]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A2': '17221', 'A3': '11499', 'A4': '14001', 'A5': '11031', 'A6': '5042', 'A7': '5662', 'A8': '17773', 'A9': '11781', 'A10': '14583', 'A11': '10973', 'A12': '4913', 'A13': '5817', 'A14': '17998', 'A15': '11664', 'A16': '13931', 'A17': '10634', 'A18': '4741', 'A19': '5905', 'A20': '359', 'A21': '353', 'A22': '355', 'A23': '375', 'A24': '60000', 'B2': '16127', 'B3': '12861', 'B4': '12519', 'B5': '9009', 'B6': '3884', 'B7': '5512', 'B8': '17251', 'B9': '14269', 'B10': '13137', 'B11': '9021', 'B12': '3944', 'B13': '5860', 'B14': '17541', 'B15': '13943', 'B16': '11672', 'B17': '9084', 'B18': '3763', 'B19': '6136', 'B20': '357', 'B21': '355', 'B22': '368', 'B23': '384', 'B24': '60000', 'C2': '10561', 'C3': '12136', 'C4': '10477', 'C5': '8298', 'C6': '4417', 'C7': '5236', 'C8': '12397', 'C9': '13424', 'C10': '10932', 'C11': '8225', 'C12': '4345', 'C13': '5111', 'C14': '12552', 'C15': '12232', 'C16': '10768', 'C17': '8223', 'C18': '4384', 'C19': '4898', 'C20': '363', 'C21': '365', 'C22': '365', 'C23': '377', 'C24': '60000', 'D2': '20244', 'D3': '26045', 'D4': '18195', 'D5': '20646', 'D6': '4751', 'D7': '9840', 'D8': '21425', 'D9': '28249', 'D10': '20002', 'D11': '21567', 'D12': '4283', 'D13': '10870', 'D14': '21885', 'D15': '29562', 'D16': '19755', 'D17': '21985', 'D18': '4144', 'D19': '10505', 'D20': '362', 'D21': '359', 'D22': '359', 'D23': '366', 'D24': '60000', 'E2': '60000', 'E3': '60000', 'E4': '60000', 'E5': '380', 'E6': '378', 'E7': '355', 'E8': '352', 'E9': '350', 'E10': '351', 'E11': '357', 'E12': '354', 'E13': '373', 'E14': '360', 'E15': '352', 'E16': '346', 'E17': '348', 'E18': '364', 'E19': '364', 'E20': '345', 'E21': '352', 'E22': '357', 'E23': '360', 'E24': '60000', 'F2': '60000', 'F3': '60000', 'F4': '60000', 'F5': '60564', 'F6': '69048', 'F7': '65184', 'F8': '5534', 'F9': '6532', 'F10': '317', 'F11': '351', 'F12': '348', 'F13': '352', 'F14': '352', 'F15': '356', 'F16': '349', 'F17': '348', 'F18': '365', 'F19': '362', 'F20': '350', 'F21': '353', 'F22': '359', 'F23': '365', 'F24': '60000', 'G2': '490', 'G3': '472', 'G4': '470', 'G5': '373', 'G6': '386', 'G7': '361', 'G8': '390', 'G9': '383', 'G10': '347', 'G11': '350', 'G12': '345', 'G13': '350', 'G14': '348', 'G15': '346', 'G16': '354', 'G17': '374', 'G18': '369', 'G19': '369', 'G20': '376', 'G21': '351', 'G22': '360', 'G23': '427', 'G24': '60000', 'H2': '361', 'H3': '357', 'H4': '350', 'H5': '370', 'H6': '368', 'H7': '344', 'H8': '353', 'H9': '382', 'H10': '349', 'H11': '350', 'H12': '349', 'H13': '344', 'H14': '348', 'H15': '364', 'H16': '366', 'H17': '366', 'H18': '358', 'H19': '358', 'H20': '371', 'H21': '365', 'H22': '358', 'H23': '360', 'H24': '348', 'I2': '360', 'I3': '393', 'I4': '350', 'I5': '356', 'I6': '355', 'I7': '346', 'I8': '342', 'I9': '371', 'I10': '354', 'I11': '346', 'I12': '343', 'I13': '365', 'I14': '352', 'I15': '343', 'I16': '359', 'I17': '370', 'I18': '347', 'I19': '356', 'I20': '368', 'I21': '361', 'I22': '357', 'I23': '359', 'I24': '355', 'J2': '355', 'J3': '354', 'J4': '353', 'J5': '347', 'J6': '361', 'J7': '348', 'J8': '354', 'J9': '364', 'J10': '346', 'J11': '348', 'J12': '350', 'J13': '346', 'J14': '346', 'J15': '350', 'J16': '354', 'J17': '382', 'J18': '366', 'J19': '373', 'J20': '375', 'J21': '357', 'J22': '362', 'J23': '359', 'J24': '358', 'K2': '355', 'K3': '365', 'K4': '363', 'K5': '357', 'K6': '345', 'K7': '365', 'K8': '351', 'K9': '343', 'K10': '350', 'K11': '352', 'K12': '410', 'K13': '349', 'K14': '353', 'K15': '348', 'K16': '347', 'K17': '350', 'K18': '348', 'K19': '353', 'K20': '359', 'K21': '358', 'K22': '385', 'K23': '361', 'K24': '365', 'L2': '356', 'L3': '370', 'L4': '434', 'L5': '367', 'L6': '356', 'L7': '344', 'L8': '348', 'L9': '349', 'L10': '346', 'L11': '352', 'L12': '352', 'L13': '350', 'L14': '352', 'L15': '350', 'L16': '356', 'L17': '353', 'L18': '352', 'L19': '352', 'L20': '354', 'L21': '364', 'L22': '363', 'L23': '362', 'L24': '365', 'M2': '35523', 'M3': '42194', 'M4': '41268', 'M5': '45355', 'M6': '33973', 'M7': '37511', 'M8': '42964', 'M9': '38607', 'M10': '43149', 'M11': '35096', 'M12': '43202', 'M13': '38412', 'M14': '39577', 'M15': '44221', 'M16': '40590', 'M17': '38641', 'M18': '44256', 'M19': '42755', 'M20': '36940', 'M21': '39234', 'M22': '38945', 'M23': '365', 'M24': '359', 'N2': '14238', 'N3': '12661', 'N4': '10997', 'N5': '14897', 'N6': '44343', 'N7': '44673', 'N8': '42276', 'N9': '13659', 'N10': '14843', 'N11': '11575', 'N12': '16180', 'N13': '45140', 'N14': '42583', 'N15': '39410', 'N16': '12932', 'N17': '13056', 'N18': '13864', 'N19': '17385', 'N20': '39281', 'N21': '41529', 'N22': '45036', 'N23': '365', 'N24': '368', 'O2': '23713', 'O3': '28041', 'O4': '15318', 'O5': '23882', 'O6': '60687', 'O7': '59264', 'O8': '57833', 'O9': '24885', 'O10': '24864', 'O11': '17279', 'O12': '29339', 'O13': '65040', 'O14': '62028', 'O15': '66900', 'O16': '27868', 'O17': '23182', 'O18': '19733', 'O19': '30516', 'O20': '63523', 'O21': '60294', 'O22': '61443', 'O23': '369', 'O24': '450', 'P2': '22804', 'P3': '24606', 'P4': '22288', 'P5': '24282', 'P6': '44329', 'P7': '41938', 'P8': '49848', 'P9': '22594', 'P10': '25235', 'P11': '21271', 'P12': '25885', 'P13': '45171', 'P14': '42280', 'P15': '35841', 'P16': '22586', 'P17': '23426', 'P18': '24155', 'P19': '26775', 'P20': '49841', 'P21': '48215', 'P22': '43113', 'P23': '360', 'P24': '370'}\n"
     ]
    }
   ],
   "source": [
    "print(name_yield_dictionnary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells_name_array = np.copy(whole_array[:,16:19])\n",
    "# print(wells_name_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(whole_array.shape[0]):\n",
    "    for j in range(16,19):\n",
    "        try:\n",
    "            whole_array[i,j] = name_yield_dictionnary[whole_array[i,j]]\n",
    "        except KeyError:\n",
    "            whole_array[i,j] = -10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 19)\n",
      "[[3.3000e-02 6.8000e-03 5.0000e+01 2.6000e-02 1.0000e+01 2.0000e+00\n",
      "  1.5000e-01 1.0000e-01 3.0000e+00 1.5000e-01 2.0000e-02 4.0000e-01\n",
      "  5.0000e+01 7.5000e-02 4.0000e+00 1.0000e+01 1.7221e+04 1.7773e+04\n",
      "  1.7998e+04]\n",
      " [1.6500e-01 6.8000e-03 5.0000e+01 2.6000e-02 1.0000e+01 2.0000e+00\n",
      "  1.5000e-01 1.0000e-01 9.0000e+00 1.5000e-01 2.0000e-02 4.0000e-01\n",
      "  5.0000e+01 3.7500e-01 1.2000e+01 1.0000e+01 1.1499e+04 1.1781e+04\n",
      "  1.1664e+04]\n",
      " [9.9000e-02 2.0400e-02 5.0000e+01 7.8000e-02 1.0000e+01 2.0000e+00\n",
      "  1.5000e-01 5.0000e-01 3.0000e+00 4.5000e-01 1.0000e-01 1.2000e+00\n",
      "  5.0000e+01 2.2500e-01 4.0000e+00 1.0000e+01 1.4001e+04 1.4583e+04\n",
      "  1.3931e+04]\n",
      " [3.3000e-02 2.0400e-02 5.0000e+01 7.8000e-02 1.0000e+01 2.0000e+00\n",
      "  1.5000e-01 5.0000e-01 9.0000e+00 4.5000e-01 6.0000e-02 2.0000e+00\n",
      "  5.0000e+01 2.2500e-01 1.2000e+01 1.0000e+01 1.1031e+04 1.0973e+04\n",
      "  1.0634e+04]\n",
      " [3.3000e-01 6.8000e-02 0.0000e+00 2.6000e-01 1.0000e+01 2.0000e+00\n",
      "  1.5000e+00 1.0000e+00 3.0000e+01 1.5000e+00 2.0000e-01 4.0000e+00\n",
      "  5.0000e+01 7.5000e-01 4.0000e+01 1.0000e+01 5.0420e+03 4.9130e+03\n",
      "  4.7410e+03]\n",
      " [3.3000e-01 6.8000e-02 5.0000e+01 2.6000e-01 1.0000e+01 2.0000e+00\n",
      "  1.5000e+00 1.0000e+00 3.0000e+01 1.5000e+00 2.0000e-01 4.0000e+00\n",
      "  5.0000e+01 7.5000e-01 4.0000e+01 1.0000e+01 5.6620e+03 5.8170e+03\n",
      "  5.9050e+03]\n",
      " [1.6500e-01 3.4000e-02 5.0000e+01 2.6000e-02 1.0000e+01 2.0000e+00\n",
      "  7.5000e-01 5.0000e-01 1.5000e+01 4.5000e-01 2.0000e-02 2.0000e+00\n",
      "  5.0000e+01 2.2500e-01 2.0000e+01 1.0000e+01 2.2804e+04 2.2594e+04\n",
      "  2.2586e+04]\n",
      " [9.9000e-02 3.4000e-02 5.0000e+01 2.6000e-02 1.0000e+01 2.0000e+00\n",
      "  7.5000e-01 3.0000e-01 1.5000e+01 7.5000e-01 2.0000e-02 1.2000e+00\n",
      "  5.0000e+01 3.7500e-01 2.0000e+01 1.0000e+01 2.4606e+04 2.5235e+04\n",
      "  2.3426e+04]\n",
      " [1.6500e-01 2.0400e-02 5.0000e+01 7.8000e-02 1.0000e+01 2.0000e+00\n",
      "  7.5000e-01 5.0000e-01 9.0000e+00 1.5000e-01 2.0000e-02 4.0000e-01\n",
      "  5.0000e+01 3.7500e-01 2.0000e+01 1.0000e+01 2.2288e+04 2.1271e+04\n",
      "  2.4155e+04]\n",
      " [3.3000e-02 6.8000e-03 5.0000e+01 2.6000e-02 1.0000e+01 2.0000e+00\n",
      "  7.5000e-01 3.0000e-01 1.5000e+01 7.5000e-01 2.0000e-02 2.0000e+00\n",
      "  5.0000e+01 3.7500e-01 1.2000e+01 1.0000e+01 2.4282e+04 2.5885e+04\n",
      "  2.6775e+04]\n",
      " [1.6500e-01 6.8000e-02 5.0000e+01 2.6000e-02 1.0000e+01 2.0000e+00\n",
      "  1.5000e+00 1.0000e-01 9.0000e+00 1.5000e+00 6.0000e-02 4.0000e+00\n",
      "  5.0000e+01 7.5000e-02 4.0000e+01 1.0000e+01 4.4329e+04 4.5171e+04\n",
      "  4.9841e+04]\n",
      " [9.9000e-02 3.4000e-02 5.0000e+01 2.6000e-02 1.0000e+01 2.0000e+00\n",
      "  1.5000e+00 1.0000e-01 9.0000e+00 1.5000e+00 1.0000e-01 4.0000e+00\n",
      "  5.0000e+01 7.5000e-02 4.0000e+01 1.0000e+01 4.1938e+04 4.2280e+04\n",
      "  4.8215e+04]\n",
      " [3.3000e-02 2.0400e-02 5.0000e+01 7.8000e-02 1.0000e+01 2.0000e+00\n",
      "  1.5000e+00 1.0000e-01 9.0000e+00 1.5000e+00 6.0000e-02 4.0000e+00\n",
      "  5.0000e+01 7.5000e-02 4.0000e+01 1.0000e+01 4.9848e+04 3.5841e+04\n",
      "  4.3113e+04]]\n"
     ]
    }
   ],
   "source": [
    "whole_array = whole_array.astype(np.float32)\n",
    "print(whole_array.shape)\n",
    "print(whole_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier_cv(row, cv):\n",
    "    x = row[16:19]\n",
    "    main_row = row[0:16]\n",
    "    mean = np.mean(x)\n",
    "    sd = np.std(x)\n",
    "    ratio = sd/mean * 100\n",
    "    if ratio > cv:\n",
    "        min_index = np.argmin(x)\n",
    "        max_index = np.argmax(x)\n",
    "        other_point_arg = 3 - min_index - max_index\n",
    "        if (x[other_point_arg] - x[min_index]) > (x[max_index] - x[other_point_arg]):\n",
    "            # Distance between medium and low is above distance between max and medium: discard lowest\n",
    "            new_x = np.concatenate((x[[other_point_arg, max_index]], np.array([-1])), axis = 0)\n",
    "        else:\n",
    "            new_x = np.concatenate((x[[min_index, other_point_arg]], np.array([-1])), axis = 0)\n",
    "        return(True, np.concatenate((main_row, new_x), axis = 0), row)\n",
    "    else:\n",
    "        return(False, row, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_array = None\n",
    "cleaned_array = None\n",
    "\n",
    "for row in whole_array:\n",
    "   # print(row.shape)\n",
    "    outlier, row, outlier_row = remove_outlier_cv(row, cv = CV)\n",
    "    if outlier:\n",
    "        print(row[16:19])\n",
    "        print(outlier_row[16:19])\n",
    "        if outliers_array is None:\n",
    "            outliers_array = np.reshape(outlier_row, (1, 19)) \n",
    "        else:\n",
    "            outliers_array = np.concatenate((outliers_array, np.reshape(outlier_row, (1, 19))), axis = 0)\n",
    "    if cleaned_array is None:\n",
    "        cleaned_array = np.reshape(row, (1, 19)) \n",
    "    else:\n",
    "        cleaned_array = np.concatenate((cleaned_array, np.reshape(row, (1, 19))), axis = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(outliers_array)\n",
    "if outliers_array is None:\n",
    "    number_outliers = 0\n",
    "else:\n",
    "    print(outliers_array.shape)\n",
    "    number_outliers = outliers_array.shape[0]\n",
    "number_total = whole_array.shape[0]\n",
    "number_bis = cleaned_array.shape[0]\n",
    "assert number_bis == number_total\n",
    "percentage = number_outliers/number_total * 100\n",
    "text = \"There are {} outliers out of {} ({}%) for CV of {}\".format(number_outliers, number_total, round(percentage, 2), CV)\n",
    "with open(comments_file, \"w\") as file_handle:\n",
    "    file_handle.write(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(outliers_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_as_dict = []\n",
    "fieldnames = [\"nad\", \"folinic_acid\", \"DNA\", \"coa\", \"RBS\", \"peg\", \"nucleo_mix\", \n",
    "              \"spermidin\", \"pga\", \"aa\", \"trna\", \"mg_gluta\", \"hepes\", \"camp\", \"K_gluta\", \"promoter\", \n",
    "              \"value_1\", \"value_2\", \"value_3\", \"plaque_name\"]\n",
    "\n",
    "if not outliers_array is None:\n",
    "    for row in outliers_array:\n",
    "        new_dict = {}\n",
    "        new_dict[\"nad\"] = round(float(row[0]), 5)\n",
    "        new_dict[\"folinic_acid\"] = round(float(row[1]), 5)\n",
    "        new_dict[\"DNA\"] = round(float(row[2]), 4)\n",
    "        new_dict[\"coa\"] = round(float(row[3]), 5)\n",
    "        new_dict[\"RBS\"] = round(float(row[4]), 4)\n",
    "        new_dict[\"peg\"] = round(float(row[5]), 5)\n",
    "        new_dict[\"nucleo_mix\"] = round(float(row[6]), 5)\n",
    "        new_dict[\"spermidin\"] = round(float(row[7]), 5)\n",
    "        new_dict[\"pga\"] = round(float(row[8]), 5)\n",
    "        new_dict[\"aa\"] = round(float(row[9]), 5)\n",
    "        new_dict[\"trna\"] = round(float(row[10]), 5)\n",
    "        new_dict[\"mg_gluta\"] = round(float(row[11]), 4)\n",
    "        new_dict[\"hepes\"] = round(float(row[12]), 4)\n",
    "        new_dict[\"camp\"] = round(float(row[13]), 4)\n",
    "        new_dict[\"K_gluta\"] = round(float(row[14]), 4)\n",
    "        new_dict[\"promoter\"] = round(float(row[15]), 4)\n",
    "        new_dict[\"value_1\"] = round(float(row[16]), 4)\n",
    "        new_dict[\"value_2\"] = round(float(row[17]), 4)\n",
    "        new_dict[\"value_3\"] = round(float(row[18]), 4)\n",
    "        new_dict[\"plaque_name\"] = plate_name\n",
    "        outliers_as_dict.append(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outliers, \"w\") as csv_handle:\n",
    "    csv_writer = csv.DictWriter(csv_handle, fieldnames, restval='', extrasaction='ignore')\n",
    "    csv_writer.writeheader()\n",
    "    for result in outliers_as_dict:\n",
    "        csv_writer.writerow(result)\n",
    "        # print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 19)\n",
      "[5042. 4913. 4741.]\n",
      "[24606. 25235. 23426.]\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_array.shape)\n",
    "\n",
    "if control_array is None:\n",
    "    print(\"controls are different\")\n",
    "    autofluo = whole_array[4,16:19]\n",
    "    autofluo_reference = np.array([5042, 4913, 4741])\n",
    "    max_extract = np.array([24606, 25235, 23426])\n",
    "else:\n",
    "    try: \n",
    "        max_extract = cleaned_array[109,16:19]  # Will be changed to reference extract in later versions of the code\n",
    "    except:\n",
    "        max_extract = cleaned_array[7,16:19]\n",
    "        \n",
    "    autofluo = whole_array[4,16:19]\n",
    "    autofluo_reference = autofluo\n",
    "\n",
    "print(autofluo)\n",
    "print(max_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_yield_mean_sd(x, autofluo, ref_fluo, autofluo_reference = None):\n",
    "    if autofluo_reference is None:\n",
    "        autofluo_reference = autofluo\n",
    "    combinations = []\n",
    "    auto_value = np.mean(autofluo)\n",
    "    auto_value_ref = np.mean(autofluo_reference)\n",
    "    \n",
    "    if ref_fluo[2] == -1:\n",
    "        ref_fluo = ref_fluo[0:2] \n",
    "    ref_value = np.mean(ref_fluo)\n",
    "    ref_value = np.mean(ref_fluo)\n",
    "    if x[2] == -1:\n",
    "        x = x[0:2]  \n",
    "    for value_x in x:\n",
    "        if value_x == np.array([-1]):\n",
    "            pass\n",
    "        else:\n",
    "            normlised_value = (value_x - auto_value)/(ref_value - auto_value_ref)\n",
    "            combinations.append(normlised_value)\n",
    "    yield_mean = np.mean(combinations)\n",
    "    yield_sd = np.std(combinations)\n",
    "    return({\"yield_mean\": yield_mean, \"yield_std\": yield_sd})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "autofluo_from_data = autofluo\n",
    "max_from_data = max_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yield_mean': 1.0, 'yield_std': 0.03840742}\n",
      "{'yield_mean': 8.381903e-09, 'yield_std': 0.0063154115}\n"
     ]
    }
   ],
   "source": [
    "# Verifications \n",
    "print(calculate_yield_mean_sd(x = max_from_data, autofluo = autofluo_from_data, \n",
    "                              ref_fluo = max_from_data, autofluo_reference = autofluo_reference))\n",
    "print(calculate_yield_mean_sd(x = autofluo_from_data, autofluo = autofluo_from_data, \n",
    "                              ref_fluo = max_from_data, autofluo_reference = autofluo_reference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array = cleaned_array[:,0:16]\n",
    "full_array = cleaned_array[:,0:19]\n",
    "mean_yield_list = []\n",
    "std_yield_list = []\n",
    "mean_list = []\n",
    "std_list = []\n",
    "\n",
    "\n",
    "for i in range(cleaned_array.shape[0]):\n",
    "    if cleaned_array[i, 18] == -1:\n",
    "        mean = np.mean(cleaned_array[i, 16:18])\n",
    "        std = np.std(cleaned_array[i, 16:18])\n",
    "    else:\n",
    "        mean = np.mean(cleaned_array[i, 16:19])\n",
    "        std = np.std(cleaned_array[i, 16:19])\n",
    "    dict_results = calculate_yield_mean_sd(cleaned_array[i, 16:19], autofluo_from_data, max_from_data)\n",
    "    yield_mean = dict_results[\"yield_mean\"]\n",
    "    yield_std = dict_results[\"yield_std\"]\n",
    "    mean_yield_list.append(yield_mean)\n",
    "    std_yield_list.append(yield_std)\n",
    "    mean_list.append(mean)\n",
    "    std_list.append(std)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 16)\n",
      "(13, 19)\n"
     ]
    }
   ],
   "source": [
    "print(new_array.shape)\n",
    "print(full_array.shape)\n",
    "full_array = np.concatenate((full_array, wells_name_array), axis = 1)\n",
    "# print(full_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_array = np.reshape(mean_list, (new_array.shape[0], 1))\n",
    "std_array = np.reshape(std_list, (new_array.shape[0], 1))\n",
    "mean_yield_array = np.reshape(mean_yield_list, (new_array.shape[0], 1))\n",
    "std_yield_array = np.reshape(std_yield_list, (new_array.shape[0], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 20)\n",
      "(13, 26)\n"
     ]
    }
   ],
   "source": [
    "array_for_saving = np.concatenate((new_array, mean_array, std_array, mean_yield_array, std_yield_array), axis = 1)\n",
    "print(array_for_saving.shape)\n",
    "array_for_saving_everything = np.concatenate((full_array, mean_array, std_array, mean_yield_array, std_yield_array), axis = 1)\n",
    "print(array_for_saving_everything.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(export_place, array_for_saving, delimiter=\";\",fmt='%.5f')\n",
    "\n",
    "# np.savetxt(all_together_place, array_for_saving_everything, delimiter=\";\",fmt='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is zero\n",
      "{'nad': 0.33, 'folinic_acid': 0.068, 'DNA': 0.0, 'coa': 0.26, 'RBS': 10.0, 'peg': 2.0, 'nucleo_mix': 1.5, 'spermidin': 1.0, 'pga': 30.0, 'aa': 1.5, 'trna': 0.2, 'mg_gluta': 4.0, 'hepes': 50.0, 'camp': 0.75, 'K_gluta': 40.0, 'promoter': 10.0, 'value_1': 5042.0, 'value_2': 4913.0, 'value_3': 4741.0, 'well_1': 'A6', 'well_2': 'A12', 'well_3': 'A18', 'mean': 4898.7, 'std': 123.3, 'yield': 0.0, 'yield_std': 0.0063, 'plaque_name': 'ORI'}\n"
     ]
    }
   ],
   "source": [
    "list_of_dict_everything = []\n",
    "list_of_dict_ML = []\n",
    "fieldnames = [\"nad\", \"folinic_acid\", \"DNA\", \"coa\", \"RBS\", \"peg\", \"nucleo_mix\", \n",
    "              \"spermidin\", \"pga\", \"aa\", \"trna\", \"mg_gluta\", \"hepes\", \"camp\", \"K_gluta\", \"promoter\", \n",
    "              \"value_1\", \"value_2\", \"value_3\", \"well_1\", \"well_2\", \"well_3\", \"mean\", \"std\", \"yield\", \"yield_std\",\n",
    "             \"plaque_name\"]\n",
    "\n",
    "for row in array_for_saving_everything:\n",
    "    new_dict = {}\n",
    "    new_dict[\"nad\"] = round(float(row[0]), 5)\n",
    "    new_dict[\"folinic_acid\"] = round(float(row[1]), 5)\n",
    "    new_dict[\"DNA\"] = round(float(row[2]), 4)\n",
    "    new_dict[\"coa\"] = round(float(row[3]), 5)\n",
    "    new_dict[\"RBS\"] = round(float(row[4]), 4)\n",
    "    new_dict[\"peg\"] = round(float(row[5]), 5)\n",
    "    new_dict[\"nucleo_mix\"] = round(float(row[6]), 5)\n",
    "    new_dict[\"spermidin\"] = round(float(row[7]), 5)\n",
    "    new_dict[\"pga\"] = round(float(row[8]), 5)\n",
    "    new_dict[\"aa\"] = round(float(row[9]), 5)\n",
    "    new_dict[\"trna\"] = round(float(row[10]), 5)\n",
    "    new_dict[\"mg_gluta\"] = round(float(row[11]), 4)\n",
    "    new_dict[\"hepes\"] = round(float(row[12]), 4)\n",
    "    new_dict[\"camp\"] = round(float(row[13]), 4)\n",
    "    new_dict[\"K_gluta\"] = round(float(row[14]), 4)\n",
    "    new_dict[\"promoter\"] = round(float(row[15]), 4)\n",
    "    new_dict[\"value_1\"] = round(float(row[16]), 4)\n",
    "    new_dict[\"value_2\"] = round(float(row[17]), 4)\n",
    "    new_dict[\"value_3\"] = round(float(row[18]), 4)\n",
    "    new_dict[\"well_1\"] = row[19]\n",
    "    new_dict[\"well_2\"] = row[20]\n",
    "    new_dict[\"well_3\"] = row[21]\n",
    "    new_dict[\"mean\"] = round(float(row[22]), 1)\n",
    "    new_dict[\"std\"] = round(float(row[23]), 1)\n",
    "    new_dict[\"yield\"] = round(float(row[24]), 4)\n",
    "    new_dict[\"yield_std\"] = round(float(row[25]), 4)\n",
    "    new_dict[\"plaque_name\"] = plate_name\n",
    "    if round(float(row[2]), 4) == 0:\n",
    "        print(\"is zero\")\n",
    "        print(new_dict)\n",
    "    else:\n",
    "        list_of_dict_ML.append(new_dict)\n",
    "    list_of_dict_everything.append(new_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(all_together_place, \"w\") as csv_handle:\n",
    "    csv_writer = csv.DictWriter(csv_handle, fieldnames, restval='', extrasaction='ignore')\n",
    "    csv_writer.writeheader()\n",
    "    for result in list_of_dict_everything:\n",
    "        csv_writer.writerow(result)\n",
    "        # print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldnames_for_ml = [\"nad\", \"folinic_acid\", \"coa\", \"nucleo_mix\", \n",
    "                    \"spermidin\", \"pga\", \"aa\", \"trna\", \"mg_gluta\", \"camp\", \"K_gluta\", \n",
    "                     \"yield\", \"yield_std\"]\n",
    "with open(export_place, \"w\") as csv_handle:\n",
    "    csv_writer = csv.DictWriter(csv_handle, fieldnames_for_ml, restval='', extrasaction='ignore')\n",
    "    csv_writer.writeheader()\n",
    "    for result in list_of_dict_ML:\n",
    "        csv_writer.writerow(result)\n",
    "        # print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['row', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23']\n"
     ]
    }
   ],
   "source": [
    "# Draw the plaque - take from the instruction AA script for more ideas.\n",
    "fieldnames_plate = ['row']\n",
    "for i in range(2,24):\n",
    "    fieldnames_plate.append(str(i))\n",
    "print(fieldnames_plate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_info, std_info, ratio_info = {}, {}, {}\n",
    "# \"well_1\", \"well_2\", \"well_3\"\n",
    "for element in list_of_dict_everything:\n",
    "    mean_info[element[\"well_1\"]] = element[\"mean\"]\n",
    "    std_info[element[\"well_1\"]] = element[\"std\"]\n",
    "    ratio_info[element[\"well_1\"]] = float(element[\"std\"])/float(element[\"mean\"]) * 100\n",
    "    mean_info[element[\"well_2\"]] = element[\"mean\"]\n",
    "    std_info[element[\"well_2\"]] = element[\"std\"]\n",
    "    ratio_info[element[\"well_2\"]] = float(element[\"std\"])/float(element[\"mean\"]) * 100\n",
    "    mean_info[element[\"well_3\"]] = element[\"mean\"]\n",
    "    std_info[element[\"well_3\"]] = element[\"std\"]\n",
    "    ratio_info[element[\"well_3\"]] = float(element[\"std\"])/float(element[\"mean\"]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(draw_mean, \"w\") as mean_drawing_file:\n",
    "    writer = csv.DictWriter(mean_drawing_file, fieldnames=fieldnames_plate, restval='0')\n",
    "    writer.writeheader()\n",
    "    current_row = 'A'\n",
    "    row = {}\n",
    "    row[\"row\"] = current_row\n",
    "    for element in sorted(mean_info.keys()):\n",
    "#         print(row)\n",
    "#         print(element)\n",
    "        if element.startswith(current_row):\n",
    "            row[element[1:]] = mean_info[element]\n",
    "        else:\n",
    "            writer.writerow(row)\n",
    "            current_row = element[0]\n",
    "            row = {\"row\": current_row}\n",
    "            row[element[1:]] = mean_info[element]\n",
    "    writer.writerow(row)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(draw_std, \"w\") as std_drawing_file:\n",
    "    writer = csv.DictWriter(std_drawing_file, fieldnames=fieldnames_plate, restval='0')\n",
    "    writer.writeheader()\n",
    "    current_row = 'A'\n",
    "    row = {}\n",
    "    row[\"row\"] = current_row\n",
    "    for element in sorted(std_info.keys()):\n",
    "#         print(row)\n",
    "#         print(element)\n",
    "        if element.startswith(current_row):\n",
    "            row[element[1:]] = std_info[element]\n",
    "        else:\n",
    "            writer.writerow(row)\n",
    "            current_row = element[0]\n",
    "            row = {\"row\": current_row}\n",
    "            row[element[1:]] = std_info[element]\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(draw_ratio, \"w\") as ratio_drawing_file:\n",
    "    writer = csv.DictWriter(ratio_drawing_file, fieldnames=fieldnames_plate, restval='0')\n",
    "    writer.writeheader()\n",
    "    current_row = 'A'\n",
    "    row = {}\n",
    "    row[\"row\"] = current_row\n",
    "    for element in sorted(ratio_info.keys()):\n",
    "#         print(row)\n",
    "#         print(element)\n",
    "        if element.startswith(current_row):\n",
    "            row[element[1:]] = ratio_info[element]\n",
    "        else:\n",
    "            writer.writerow(row)\n",
    "            current_row = element[0]\n",
    "            row = {\"row\": current_row}\n",
    "            row[element[1:]] = ratio_info[element]\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
