{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim here is to start the proper extraction process as was dicussed with Olivier:\n",
    "- CV 30 as a limit for outliers\n",
    "- verification of duplicates between plates\n",
    "- mean of zero and reference for yield calculations, and not all combinations\n",
    "- once it's proven to work the other scripts will go to archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The aim of this file is to extract yield values from the TECAN and map it to the correct file\n",
    "import numpy as np\n",
    "import csv\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I'm extracting TECAN into a dictionnary (for starters)\n",
    "\n",
    "plate_name = \"spectinomycin\"\n",
    "result_name = \"tecan_results\"\n",
    "\n",
    "# plate_name = \"plate_AL_1b\"\n",
    "# result_name = \"plate_AL_1b_raw\"\n",
    "\n",
    "CV = 30\n",
    "folder_result = \"raw_data\"\n",
    "\n",
    "localisation = \"{}/{}.csv\".format(folder_result, result_name)\n",
    "data_source = \"{}/{}_concentrations_reconstituted.csv\".format(folder_result, plate_name)\n",
    "export_place = \"{}/{}_yield_and_std.csv\".format(folder_result, plate_name)\n",
    "all_together_place = \"{}/{}_everything.csv\".format(folder_result, plate_name)\n",
    "draw_mean = \"{}/{}_draw_mean.csv\".format(folder_result, plate_name)\n",
    "draw_std =  \"{}/{}_draw_std.csv\".format(folder_result, plate_name)\n",
    "draw_ratio =  \"{}/{}_draw_ratio.csv\".format(folder_result, plate_name)\n",
    "outliers =  \"{}/{}_outliers.csv\".format(folder_result, plate_name)\n",
    "comments_file = \"{}/{}_comments.txt\".format(folder_result, plate_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_current_data = np.genfromtxt(data_source, delimiter=',', skip_header  = 1, dtype = \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A6\n",
      "A12\n",
      "A18\n",
      "OrderedDict([('nad', '0.099'), ('folinic_acid', '0.034'), ('DNA', '50'), ('coa', '0.026'), ('RBS', '10'), ('peg', '2'), ('nucleo_mix', '0.75'), ('spermidin', '0.3'), ('pga', '15'), ('aa', '0.75'), ('trna', '0.02'), ('mg_gluta', '1.2'), ('hepes', '50'), ('camp', '0.375'), ('K_gluta', '20'), ('promoter', '10'), ('name', 'P3')])\n"
     ]
    }
   ],
   "source": [
    "wells_information = {}\n",
    "\n",
    "with open(data_source) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if row[\"name\"] == \"\":\n",
    "            pass\n",
    "        if row[\"name\"] == \"P3\":\n",
    "            print(row)\n",
    "            wells_information[row[\"name\"]] = row\n",
    "        else:\n",
    "            wells_information[row[\"name\"]] = row\n",
    "            if row[\"DNA\"] == \"0\":\n",
    "                print(row[\"name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def present_in_array(new_sample, array):\n",
    "    present = False\n",
    "    new_sample = np.reshape(np.array(new_sample), (1,16))\n",
    "    for i in range(array.shape[0]):\n",
    "        if np.array_equiv(array[i,:],new_sample):\n",
    "            present = True\n",
    "            break\n",
    "    \n",
    "            \n",
    "    return(present, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting control and plate info separately information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DNA row is 3\n",
      "Empty DNA row (from row) is 3\n",
      "Reference row (from row) is 4\n",
      "C9 is already present and it a duplciate of well C5\n",
      "G3 is 36\n",
      "M18 is 85\n",
      "P3 is 0\n",
      "P3 is 0\n"
     ]
    }
   ],
   "source": [
    "control_array = None\n",
    "plate_array = None\n",
    "control_max_array = None\n",
    "\n",
    "for well, row in wells_information.items():\n",
    "    this_sample_conc = [row[\"nad\"],\n",
    "                        row[\"folinic_acid\"], \n",
    "                        row[\"DNA\"], \n",
    "                        row[\"coa\"], \n",
    "                        row[\"RBS\"], \n",
    "                        row[\"peg\"], \n",
    "                        row[\"nucleo_mix\"],\n",
    "                        row[\"spermidin\"],\n",
    "                        row[\"pga\"],\n",
    "                        row[\"aa\"],\n",
    "                        row[\"trna\"],\n",
    "                        row[\"mg_gluta\"],\n",
    "                        row[\"hepes\"],\n",
    "                        row[\"camp\"],\n",
    "                        row[\"K_gluta\"],\n",
    "                        row[\"promoter\"]\n",
    "                         ]\n",
    "    if well.startswith(\"A\"):        \n",
    "        if control_array is None:\n",
    "            this_sample_conc.extend([well, '', ''])\n",
    "            this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "            control_array = this_sample_conc \n",
    "        else:\n",
    "            # already present in the array. \n",
    "            # Either file up a new line or...\n",
    "            present, i = present_in_array(this_sample_conc, control_array[:, 0:16])\n",
    "    #         present, i = present_in_array(this_sample_conc[:, 0:16], array_with_wells[:, 0:16])\n",
    "            if not present:    \n",
    "    #             if well == 'M21':\n",
    "    #                 print(i)\n",
    "                if well == 'A6':\n",
    "                    print(\"Empty DNA row is {}\".format(i))\n",
    "                if float(row[\"DNA\"]) == 0:\n",
    "                    print(\"Empty DNA row (from row) is {}\".format(i))\n",
    "                if well == 'M6':\n",
    "                    print(\"Reference row is {}\".format(i))\n",
    "                if float(row[\"K_gluta\"]) == 40 and float(row[\"DNA\"]) != 0:\n",
    "                    print(\"Reference row (from row) is {}\".format(i))\n",
    "                this_sample_conc.extend([well, '', ''])\n",
    "                this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "                control_array = np.concatenate((control_array, this_sample_conc), axis = 0)\n",
    "            else:\n",
    "                if control_array[i,17] == '':\n",
    "                    control_array[i,17] = well\n",
    "                elif control_array[i,18] == '':\n",
    "                    control_array[i,18] = well\n",
    "                else:\n",
    "                    # print(\"{}, {}, {}\".format(well, row, array_with_wells[i,:]))\n",
    "                    print(row[\"name\"])\n",
    "                    print(\"this makes sense, it's the max\")\n",
    "    elif well.startswith(\"P\"): \n",
    "        if control_max_array is None:\n",
    "            this_sample_conc.extend([well, '', ''])\n",
    "            this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "            control_max_array = this_sample_conc \n",
    "        else:\n",
    "            # already present in the array. \n",
    "            # Either file up a new line or...\n",
    "            present, i = present_in_array(this_sample_conc, control_max_array[:, 0:16])\n",
    "    #         present, i = present_in_array(this_sample_conc[:, 0:16], array_with_wells[:, 0:16])\n",
    "            if well == 'P3':\n",
    "                print(\"P3 is {}\".format(i))\n",
    "            if not present: \n",
    "                this_sample_conc.extend([well, '', '']) \n",
    "                if well == 'P3':\n",
    "                    print(\"P3 is {}\".format(i))\n",
    "                this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "                control_max_array = np.concatenate((control_max_array, this_sample_conc), axis = 0)\n",
    "            else:\n",
    "                if control_max_array[i,17] == '':\n",
    "                    control_max_array[i,17] = well\n",
    "                elif control_max_array[i,18] == '':\n",
    "                    control_max_array[i,18] = well\n",
    "                else:\n",
    "                    # print(\"{}, {}, {}\".format(well, row, array_with_wells[i,:]))\n",
    "                    print(row[\"name\"])\n",
    "                    print(\"this makes sense, it's the max\")\n",
    "    else:\n",
    "        if plate_array is None:\n",
    "            this_sample_conc.extend([well, '', ''])\n",
    "            this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "            plate_array = this_sample_conc\n",
    "        else:\n",
    "            # already present in the array. \n",
    "            # Either file up a new line or...\n",
    "            present, i = present_in_array(this_sample_conc, plate_array[:, 0:16])\n",
    "    #         present, i = present_in_array(this_sample_conc[:, 0:16], array_with_wells[:, 0:16])\n",
    "            if not present:    \n",
    "                if well == 'G3':\n",
    "                    print(\"G3 is {}\".format(i))\n",
    "                if well == 'M6':\n",
    "                    print(\"M6 is {}\".format(i))\n",
    "                if well == 'M18':\n",
    "                    print(\"M18 is {}\".format(i))\n",
    "#                 if well == 'C8':\n",
    "#                     print(i)\n",
    "                this_sample_conc.extend([well, '', ''])\n",
    "                this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "                plate_array = np.concatenate((plate_array, this_sample_conc), axis = 0)\n",
    "            else:\n",
    "                if plate_array[i,17] == '':\n",
    "                    plate_array[i,17] = well\n",
    "                elif plate_array[i,18] == '':\n",
    "                    plate_array[i,18] = well\n",
    "                else:\n",
    "                    print(\"{} is already present and it a duplciate of well {}\".format(row[\"name\"], plate_array[i,16]))\n",
    "                    this_sample_conc.extend([well, '', ''])\n",
    "                    this_sample_conc = np.reshape(this_sample_conc, (1, 19))\n",
    "                    plate_array = np.concatenate((this_sample_conc, plate_array), axis = 0)\n",
    "                    # print(row)\n",
    "                    # print(\"this makes sense, it's the max\")\n",
    "# print(plate_array.shape)\n",
    "# print(plate_array[1:15, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.033' '0.0068' '50' '0.026' '10' '2' '0.15' '0.1' '3' '0.15' '0.02'\n",
      "  '0.4' '50' '0.075' '4' '10' 'A2' 'A8' 'A14']\n",
      " ['0.165' '0.0068' '50' '0.026' '10' '2' '0.15' '0.1' '9' '0.15' '0.02'\n",
      "  '0.4' '50' '0.375' '12' '10' 'A3' 'A9' 'A15']\n",
      " ['0.099' '0.0204' '50' '0.078' '10' '2' '0.15' '0.5' '3' '0.45' '0.1'\n",
      "  '1.2' '50' '0.225' '4' '10' 'A4' 'A10' 'A16']\n",
      " ['0.033' '0.0204' '50' '0.078' '10' '2' '0.15' '0.5' '9' '0.45' '0.06'\n",
      "  '2' '50' '0.225' '12' '10' 'A5' 'A11' 'A17']\n",
      " ['0.33' '0.068' '0' '0.26' '10' '2' '1.5' '1' '30' '1.5' '0.2' '4' '50'\n",
      "  '0.75' '40' '10' 'A6' 'A12' 'A18']\n",
      " ['0.33' '0.068' '50' '0.26' '10' '2' '1.5' '1' '30' '1.5' '0.2' '4' '50'\n",
      "  '0.75' '40' '10' 'A7' 'A13' 'A19']]\n",
      "['0.33' '0.068' '0' '0.26' '10' '2' '1.5' '1' '30' '1.5' '0.2' '4' '50'\n",
      " '0.75' '40' '10' 'A6' 'A12' 'A18']\n",
      "['0.33' '0.068' '50' '0.26' '10' '2' '1.5' '1' '30' '1.5' '0.2' '4' '50'\n",
      " '0.75' '40' '10' 'A7' 'A13' 'A19']\n",
      "['0.33' '0.068' '0' '0.26' '10' '2' '1.5' '1' '30' '1.5' '0.2' '4' '50'\n",
      " '0.75' '40' '10' 'A6' 'A12' 'A18']\n",
      "['0.33' '0.068' '50' '0.26' '10' '2' '1.5' '1' '30' '1.5' '0.2' '4' '50'\n",
      " '0.75' '40' '10' 'A7' 'A13' 'A19']\n"
     ]
    }
   ],
   "source": [
    "print(control_array)\n",
    "if control_array is None:\n",
    "    whole_array = plate_array\n",
    "else:\n",
    "    print(control_array[4,])\n",
    "    print(control_array[5,])\n",
    "    try:\n",
    "        whole_array = np.concatenate((control_array, plate_array, control_max_array), axis = 0)\n",
    "    except ValueError:\n",
    "        whole_array = np.concatenate((control_array, control_max_array), axis = 0)\n",
    "    print(whole_array[4,])\n",
    "    print(whole_array[5,])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 19)\n"
     ]
    }
   ],
   "source": [
    "print(whole_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing named wells with their values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_yield_dictionnary = {}\n",
    "\n",
    "with open(localisation) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        name_yield_dictionnary[row[\"name\"]] = row[\"Time_5\"]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A2': '10000', 'A3': '8169', 'A4': '9846', 'A5': '9731', 'A6': '4138', 'A7': '4761', 'A8': '11503', 'A9': '10904', 'A10': '10807', 'A11': '8895', 'A12': '3612', 'A13': '4859', 'A14': '12063', 'A15': '11329', 'A16': '10069', 'A17': '7458', 'A18': '5051', 'A19': '4481', 'A20': '473', 'A21': '458', 'A22': '508', 'A23': '473', 'A24': '462', 'B2': '11356', 'B3': '11813', 'B4': '11110', 'B5': '10238', 'B6': '9700', 'B7': '9464', 'B8': '13364', 'B9': '12894', 'B10': '12695', 'B11': '8688', 'B12': '8830', 'B13': '8937', 'B14': '12334', 'B15': '12991', 'B16': '14391', 'B17': '12479', 'B18': '13160', 'B19': '13022', 'B20': '13038', 'B21': '13421', 'B22': '13882', 'B23': '10921', 'B24': '476', 'C2': '12364', 'C3': '11545', 'C4': '14872', 'C5': '15051', 'C6': '13957', 'C7': '13815', 'C8': '14437', 'C9': '14414', 'C10': '13821', 'C11': '14714', 'C12': '14767', 'C13': '8844', 'C14': '8880', 'C15': '8886', 'C16': '13638', 'C17': '11706', 'C18': '13747', 'C19': '11848', 'C20': '12691', 'C21': '10022', 'C22': '12453', 'C23': '12619', 'C24': '476', 'D2': '13276', 'D3': '12486', 'D4': '13757', 'D5': '13532', 'D6': '12867', 'D7': '12269', 'D8': '11808', 'D9': '12590', 'D10': '13557', 'D11': '13935', 'D12': '12514', 'D13': '12756', 'D14': '13339', 'D15': '12324', 'D16': '13371', 'D17': '12863', 'D18': '13217', 'D19': '12888', 'D20': '13047', 'D21': '12682', 'D22': '12880', 'D23': '11781', 'D24': '486', 'E2': '13758', 'E3': '13930', 'E4': '13063', 'E5': '14714', 'E6': '15235', 'E7': '15075', 'E8': '13711', 'E9': '14201', 'E10': '14345', 'E11': '14500', 'E12': '13999', 'E13': '14769', 'E14': '14953', 'E15': '15014', 'E16': '15245', 'E17': '15716', 'E18': '14883', 'E19': '14274', 'E20': '15394', 'E21': '14674', 'E22': '13007', 'E23': '14751', 'E24': '484', 'F2': '15318', 'F3': '14932', 'F4': '15070', 'F5': '14711', 'F6': '15182', 'F7': '15505', 'F8': '15651', 'F9': '14934', 'F10': '12594', 'F11': '14004', 'F12': '12929', 'F13': '14486', 'F14': '13730', 'F15': '14333', 'F16': '8324', 'F17': '8367', 'F18': '7643', 'F19': '12248', 'F20': '12044', 'F21': '11408', 'F22': '13282', 'F23': '13060', 'F24': '484', 'G2': '12503', 'G3': '12973', 'G4': '13397', 'G5': '13072', 'G6': '14055', 'G7': '10814', 'G8': '14101', 'G9': '10228', 'G10': '13581', 'G11': '10559', 'G12': '12894', 'G13': '12154', 'G14': '12722', 'G15': '13836', 'G16': '13184', 'G17': '12882', 'G18': '13722', 'G19': '14280', 'G20': '13580', 'G21': '7131', 'G22': '7550', 'G23': '7678', 'G24': '480', 'H2': '14149', 'H3': '13678', 'H4': '13885', 'H5': '14316', 'H6': '14623', 'H7': '14229', 'H8': '13687', 'H9': '13172', 'H10': '13175', 'H11': '13635', 'H12': '13779', 'H13': '14478', 'H14': '12998', 'H15': '13193', 'H16': '12758', 'H17': '7736', 'H18': '7419', 'H19': '7460', 'H20': '12842', 'H21': '13005', 'H22': '12585', 'H23': '12391', 'H24': '477', 'I2': '12983', 'I3': '12428', 'I4': '14058', 'I5': '13553', 'I6': '13901', 'I7': '12979', 'I8': '14432', 'I9': '13562', 'I10': '7035', 'I11': '7280', 'I12': '7878', 'I13': '12613', 'I14': '12612', 'I15': '12792', 'I16': '15410', 'I17': '15408', 'I18': '15481', 'I19': '15294', 'I20': '15153', 'I21': '14690', 'I22': '14349', 'I23': '14043', 'I24': '481', 'J2': '14811', 'J3': '13420', 'J4': '13277', 'J5': '13605', 'J6': '12960', 'J7': '12932', 'J8': '13520', 'J9': '7529', 'J10': '15341', 'J11': '6980', 'J12': '7909', 'J13': '15097', 'J14': '7577', 'J15': '7858', 'J16': '15190', 'J17': '7100', 'J18': '10209', 'J19': '10557', 'J20': '10025', 'J21': '9839', 'J22': '9439', 'J23': '9341', 'J24': '490', 'K2': '7487', 'K3': '13441', 'K4': '7563', 'K5': '13297', 'K6': '7946', 'K7': '13132', 'K8': '13331', 'K9': '12993', 'K10': '11301', 'K11': '13442', 'K12': '12962', 'K13': '13579', 'K14': '13006', 'K15': '14132', 'K16': '13467', 'K17': '13628', 'K18': '13323', 'K19': '13402', 'K20': '14619', 'K21': '14164', 'K22': '13663', 'K23': '14874', 'K24': '516', 'L2': '14595', 'L3': '14548', 'L4': '13744', 'L5': '13314', 'L6': '13662', 'L7': '13848', 'L8': '13664', 'L9': '14907', 'L10': '15426', 'L11': '14144', 'L12': '12410', 'L13': '14272', 'L14': '14637', 'L15': '12885', 'L16': '13880', 'L17': '13805', 'L18': '14894', 'L19': '12087', 'L20': '12587', 'L21': '12752', 'L22': '14380', 'L23': '14648', 'L24': '497', 'M2': '13011', 'M3': '13758', 'M4': '14536', 'M5': '14553', 'M6': '14686', 'M7': '15469', 'M8': '14900', 'M9': '15072', 'M10': '15105', 'M11': '15168', 'M12': '15082', 'M13': '15771', 'M14': '14606', 'M15': '13532', 'M16': '13781', 'M17': '12873', 'M18': '14227', 'M19': '14050', 'M20': '14587', 'M21': '13309', 'M22': '13824', 'M23': '14657', 'M24': '484', 'N2': '13804', 'N3': '14026', 'N4': '14592', 'N5': '13720', 'N6': '15948', 'N7': '15234', 'N8': '16072', 'N9': '13629', 'N10': '14326', 'N11': '15839', 'N12': '14562', 'N13': '15805', 'N14': '13709', 'N15': '14974', 'N16': '15781', 'N17': '14697', 'N18': '14356', 'N19': '12119', 'N20': '12602', 'N21': '12812', 'N22': '12680', 'N23': '13043', 'N24': '492', 'O2': '12212', 'O3': '13141', 'O4': '12411', 'O5': '13291', 'O6': '14549', 'O7': '13357', 'O8': '14436', 'O9': '14070', 'O10': '15413', 'O11': '13598', 'O12': '15241', 'O13': '13966', 'O14': '14750', 'O15': '15011', 'O16': '8348', 'O17': '8222', 'O18': '7736', 'O19': '4100', 'O20': '4281', 'O21': '4355', 'O22': '487', 'O23': '492', 'O24': '503', 'P2': '12968', 'P3': '12370', 'P4': '10401', 'P5': '13327', 'P6': '15287', 'P7': '15089', 'P8': '15148', 'P9': '10061', 'P10': '11746', 'P11': '11155', 'P12': '9778', 'P13': '14917', 'P14': '15273', 'P15': '16236', 'P16': '11126', 'P17': '11132', 'P18': '11808', 'P19': '12860', 'P20': '13629', 'P21': '13825', 'P22': '13810', 'P23': '488', 'P24': '482'}\n"
     ]
    }
   ],
   "source": [
    "print(name_yield_dictionnary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells_name_array = np.copy(whole_array[:,16:19])\n",
    "# print(wells_name_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(whole_array.shape[0]):\n",
    "    for j in range(16,19):\n",
    "        try:\n",
    "            whole_array[i,j] = name_yield_dictionnary[whole_array[i,j]]\n",
    "        except KeyError:\n",
    "            whole_array[i,j] = -10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 19)\n",
      "[[3.3000e-02 6.8000e-03 5.0000e+01 ... 1.0000e+04 1.1503e+04 1.2063e+04]\n",
      " [1.6500e-01 6.8000e-03 5.0000e+01 ... 8.1690e+03 1.0904e+04 1.1329e+04]\n",
      " [9.9000e-02 2.0400e-02 5.0000e+01 ... 9.8460e+03 1.0807e+04 1.0069e+04]\n",
      " ...\n",
      " [1.6500e-01 6.8000e-02 5.0000e+01 ... 1.5287e+04 1.4917e+04 1.3629e+04]\n",
      " [9.9000e-02 3.4000e-02 5.0000e+01 ... 1.5089e+04 1.5273e+04 1.3825e+04]\n",
      " [3.3000e-02 2.0400e-02 5.0000e+01 ... 1.5148e+04 1.6236e+04 1.3810e+04]]\n"
     ]
    }
   ],
   "source": [
    "whole_array = whole_array.astype(np.float32)\n",
    "print(whole_array.shape)\n",
    "print(whole_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier_cv(row, cv):\n",
    "    x = row[16:19]\n",
    "    main_row = row[0:16]\n",
    "    mean = np.mean(x)\n",
    "    sd = np.std(x)\n",
    "    ratio = sd/mean * 100\n",
    "    if ratio > cv:\n",
    "        min_index = np.argmin(x)\n",
    "        max_index = np.argmax(x)\n",
    "        other_point_arg = 3 - min_index - max_index\n",
    "        if (x[other_point_arg] - x[min_index]) > (x[max_index] - x[other_point_arg]):\n",
    "            # Distance between medium and low is above distance between max and medium: discard lowest\n",
    "            new_x = np.concatenate((x[[other_point_arg, max_index]], np.array([-1])), axis = 0)\n",
    "        else:\n",
    "            new_x = np.concatenate((x[[min_index, other_point_arg]], np.array([-1])), axis = 0)\n",
    "        return(True, np.concatenate((main_row, new_x), axis = 0), row)\n",
    "    else:\n",
    "        return(False, row, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_array = None\n",
    "cleaned_array = None\n",
    "\n",
    "for row in whole_array:\n",
    "   # print(row.shape)\n",
    "    outlier, row, outlier_row = remove_outlier_cv(row, cv = CV)\n",
    "    if outlier:\n",
    "        print(row[16:19])\n",
    "        print(outlier_row[16:19])\n",
    "        if outliers_array is None:\n",
    "            outliers_array = np.reshape(outlier_row, (1, 19)) \n",
    "        else:\n",
    "            outliers_array = np.concatenate((outliers_array, np.reshape(outlier_row, (1, 19))), axis = 0)\n",
    "    if cleaned_array is None:\n",
    "        cleaned_array = np.reshape(row, (1, 19)) \n",
    "    else:\n",
    "        cleaned_array = np.concatenate((cleaned_array, np.reshape(row, (1, 19))), axis = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(outliers_array)\n",
    "if outliers_array is None:\n",
    "    number_outliers = 0\n",
    "else:\n",
    "    print(outliers_array.shape)\n",
    "    number_outliers = outliers_array.shape[0]\n",
    "number_total = whole_array.shape[0]\n",
    "number_bis = cleaned_array.shape[0]\n",
    "assert number_bis == number_total\n",
    "percentage = number_outliers/number_total * 100\n",
    "text = \"There are {} outliers out of {} ({}%) for CV of {}\".format(number_outliers, number_total, round(percentage, 2), CV)\n",
    "with open(comments_file, \"w\") as file_handle:\n",
    "    file_handle.write(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(outliers_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_as_dict = []\n",
    "fieldnames = [\"nad\", \"folinic_acid\", \"DNA\", \"coa\", \"RBS\", \"peg\", \"nucleo_mix\", \n",
    "              \"spermidin\", \"pga\", \"aa\", \"trna\", \"mg_gluta\", \"hepes\", \"camp\", \"K_gluta\", \"promoter\", \n",
    "              \"value_1\", \"value_2\", \"value_3\", \"plaque_name\"]\n",
    "\n",
    "if not outliers_array is None:\n",
    "    for row in outliers_array:\n",
    "        new_dict = {}\n",
    "        new_dict[\"nad\"] = round(float(row[0]), 5)\n",
    "        new_dict[\"folinic_acid\"] = round(float(row[1]), 5)\n",
    "        new_dict[\"DNA\"] = round(float(row[2]), 4)\n",
    "        new_dict[\"coa\"] = round(float(row[3]), 5)\n",
    "        new_dict[\"RBS\"] = round(float(row[4]), 4)\n",
    "        new_dict[\"peg\"] = round(float(row[5]), 5)\n",
    "        new_dict[\"nucleo_mix\"] = round(float(row[6]), 5)\n",
    "        new_dict[\"spermidin\"] = round(float(row[7]), 5)\n",
    "        new_dict[\"pga\"] = round(float(row[8]), 5)\n",
    "        new_dict[\"aa\"] = round(float(row[9]), 5)\n",
    "        new_dict[\"trna\"] = round(float(row[10]), 5)\n",
    "        new_dict[\"mg_gluta\"] = round(float(row[11]), 4)\n",
    "        new_dict[\"hepes\"] = round(float(row[12]), 4)\n",
    "        new_dict[\"camp\"] = round(float(row[13]), 4)\n",
    "        new_dict[\"K_gluta\"] = round(float(row[14]), 4)\n",
    "        new_dict[\"promoter\"] = round(float(row[15]), 4)\n",
    "        new_dict[\"value_1\"] = round(float(row[16]), 4)\n",
    "        new_dict[\"value_2\"] = round(float(row[17]), 4)\n",
    "        new_dict[\"value_3\"] = round(float(row[18]), 4)\n",
    "        new_dict[\"plaque_name\"] = plate_name\n",
    "        outliers_as_dict.append(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outliers, \"w\") as csv_handle:\n",
    "    csv_writer = csv.DictWriter(csv_handle, fieldnames, restval='', extrasaction='ignore')\n",
    "    csv_writer.writeheader()\n",
    "    for result in outliers_as_dict:\n",
    "        csv_writer.writerow(result)\n",
    "        # print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 19)\n",
      "[4138. 3612. 5051.]\n",
      "[12370. 11746. 11132.]\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_array.shape)\n",
    "\n",
    "if control_array is None:\n",
    "    print(\"controls are different\")\n",
    "    autofluo = whole_array[4,16:19]\n",
    "    autofluo_reference = np.array([5042, 4913, 4741])\n",
    "    max_extract = np.array([24606, 25235, 23426])\n",
    "else:\n",
    "    try: \n",
    "        max_extract = cleaned_array[109,16:19]  # Will be changed to reference extract in later versions of the code\n",
    "    except:\n",
    "        max_extract = cleaned_array[7,16:19]\n",
    "        \n",
    "    autofluo = whole_array[4,16:19]\n",
    "    autofluo_reference = autofluo\n",
    "\n",
    "print(autofluo)\n",
    "print(max_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_yield_mean_sd(x, autofluo, ref_fluo, autofluo_reference = None):\n",
    "    if autofluo_reference is None:\n",
    "        autofluo_reference = autofluo\n",
    "    combinations = []\n",
    "    auto_value = np.mean(autofluo)\n",
    "    auto_value_ref = np.mean(autofluo_reference)\n",
    "    \n",
    "    if ref_fluo[2] == -1:\n",
    "        ref_fluo = ref_fluo[0:2] \n",
    "    ref_value = np.mean(ref_fluo)\n",
    "    ref_value = np.mean(ref_fluo)\n",
    "    if x[2] == -1:\n",
    "        x = x[0:2]  \n",
    "    for value_x in x:\n",
    "        if value_x == np.array([-1]):\n",
    "            pass\n",
    "        else:\n",
    "            normlised_value = (value_x - auto_value)/(ref_value - auto_value_ref)\n",
    "            combinations.append(normlised_value)\n",
    "    yield_mean = np.mean(combinations)\n",
    "    yield_sd = np.std(combinations)\n",
    "    return({\"yield_mean\": yield_mean, \"yield_std\": yield_sd})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "autofluo_from_data = autofluo\n",
    "max_from_data = max_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yield_mean': 1.0, 'yield_std': 0.06754801}\n",
      "{'yield_mean': 0.0, 'yield_std': 0.079454996}\n"
     ]
    }
   ],
   "source": [
    "# Verifications \n",
    "print(calculate_yield_mean_sd(x = max_from_data, autofluo = autofluo_from_data, \n",
    "                              ref_fluo = max_from_data, autofluo_reference = autofluo_reference))\n",
    "print(calculate_yield_mean_sd(x = autofluo_from_data, autofluo = autofluo_from_data, \n",
    "                              ref_fluo = max_from_data, autofluo_reference = autofluo_reference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array = cleaned_array[:,0:16]\n",
    "full_array = cleaned_array[:,0:19]\n",
    "mean_yield_list = []\n",
    "std_yield_list = []\n",
    "mean_list = []\n",
    "std_list = []\n",
    "\n",
    "\n",
    "for i in range(cleaned_array.shape[0]):\n",
    "    if cleaned_array[i, 18] == -1:\n",
    "        mean = np.mean(cleaned_array[i, 16:18])\n",
    "        std = np.std(cleaned_array[i, 16:18])\n",
    "    else:\n",
    "        mean = np.mean(cleaned_array[i, 16:19])\n",
    "        std = np.std(cleaned_array[i, 16:19])\n",
    "    dict_results = calculate_yield_mean_sd(cleaned_array[i, 16:19], autofluo_from_data, max_from_data)\n",
    "    yield_mean = dict_results[\"yield_mean\"]\n",
    "    yield_std = dict_results[\"yield_std\"]\n",
    "    mean_yield_list.append(yield_mean)\n",
    "    std_yield_list.append(yield_std)\n",
    "    mean_list.append(mean)\n",
    "    std_list.append(std)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 16)\n",
      "(115, 19)\n"
     ]
    }
   ],
   "source": [
    "print(new_array.shape)\n",
    "print(full_array.shape)\n",
    "full_array = np.concatenate((full_array, wells_name_array), axis = 1)\n",
    "# print(full_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_array = np.reshape(mean_list, (new_array.shape[0], 1))\n",
    "std_array = np.reshape(std_list, (new_array.shape[0], 1))\n",
    "mean_yield_array = np.reshape(mean_yield_list, (new_array.shape[0], 1))\n",
    "std_yield_array = np.reshape(std_yield_list, (new_array.shape[0], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 20)\n",
      "(115, 26)\n"
     ]
    }
   ],
   "source": [
    "array_for_saving = np.concatenate((new_array, mean_array, std_array, mean_yield_array, std_yield_array), axis = 1)\n",
    "print(array_for_saving.shape)\n",
    "array_for_saving_everything = np.concatenate((full_array, mean_array, std_array, mean_yield_array, std_yield_array), axis = 1)\n",
    "print(array_for_saving_everything.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(export_place, array_for_saving, delimiter=\";\",fmt='%.5f')\n",
    "\n",
    "# np.savetxt(all_together_place, array_for_saving_everything, delimiter=\";\",fmt='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is zero\n",
      "{'nad': 0.33, 'folinic_acid': 0.068, 'DNA': 0.0, 'coa': 0.26, 'RBS': 10.0, 'peg': 2.0, 'nucleo_mix': 1.5, 'spermidin': 1.0, 'pga': 30.0, 'aa': 1.5, 'trna': 0.2, 'mg_gluta': 4.0, 'hepes': 50.0, 'camp': 0.75, 'K_gluta': 40.0, 'promoter': 10.0, 'value_1': 4138.0, 'value_2': 3612.0, 'value_3': 5051.0, 'well_1': 'A6', 'well_2': 'A12', 'well_3': 'A18', 'mean': 4267.0, 'std': 594.5, 'yield': 0.0, 'yield_std': 0.0795, 'plaque_name': 'spectinomycin'}\n"
     ]
    }
   ],
   "source": [
    "list_of_dict_everything = []\n",
    "list_of_dict_ML = []\n",
    "fieldnames = [\"nad\", \"folinic_acid\", \"DNA\", \"coa\", \"RBS\", \"peg\", \"nucleo_mix\", \n",
    "              \"spermidin\", \"pga\", \"aa\", \"trna\", \"mg_gluta\", \"hepes\", \"camp\", \"K_gluta\", \"promoter\", \n",
    "              \"value_1\", \"value_2\", \"value_3\", \"well_1\", \"well_2\", \"well_3\", \"mean\", \"std\", \"yield\", \"yield_std\",\n",
    "             \"plaque_name\"]\n",
    "\n",
    "for row in array_for_saving_everything:\n",
    "    new_dict = {}\n",
    "    new_dict[\"nad\"] = round(float(row[0]), 5)\n",
    "    new_dict[\"folinic_acid\"] = round(float(row[1]), 5)\n",
    "    new_dict[\"DNA\"] = round(float(row[2]), 4)\n",
    "    new_dict[\"coa\"] = round(float(row[3]), 5)\n",
    "    new_dict[\"RBS\"] = round(float(row[4]), 4)\n",
    "    new_dict[\"peg\"] = round(float(row[5]), 5)\n",
    "    new_dict[\"nucleo_mix\"] = round(float(row[6]), 5)\n",
    "    new_dict[\"spermidin\"] = round(float(row[7]), 5)\n",
    "    new_dict[\"pga\"] = round(float(row[8]), 5)\n",
    "    new_dict[\"aa\"] = round(float(row[9]), 5)\n",
    "    new_dict[\"trna\"] = round(float(row[10]), 5)\n",
    "    new_dict[\"mg_gluta\"] = round(float(row[11]), 4)\n",
    "    new_dict[\"hepes\"] = round(float(row[12]), 4)\n",
    "    new_dict[\"camp\"] = round(float(row[13]), 4)\n",
    "    new_dict[\"K_gluta\"] = round(float(row[14]), 4)\n",
    "    new_dict[\"promoter\"] = round(float(row[15]), 4)\n",
    "    new_dict[\"value_1\"] = round(float(row[16]), 4)\n",
    "    new_dict[\"value_2\"] = round(float(row[17]), 4)\n",
    "    new_dict[\"value_3\"] = round(float(row[18]), 4)\n",
    "    new_dict[\"well_1\"] = row[19]\n",
    "    new_dict[\"well_2\"] = row[20]\n",
    "    new_dict[\"well_3\"] = row[21]\n",
    "    new_dict[\"mean\"] = round(float(row[22]), 1)\n",
    "    new_dict[\"std\"] = round(float(row[23]), 1)\n",
    "    new_dict[\"yield\"] = round(float(row[24]), 4)\n",
    "    new_dict[\"yield_std\"] = round(float(row[25]), 4)\n",
    "    new_dict[\"plaque_name\"] = plate_name\n",
    "    if round(float(row[2]), 4) == 0:\n",
    "        print(\"is zero\")\n",
    "        print(new_dict)\n",
    "    else:\n",
    "        list_of_dict_ML.append(new_dict)\n",
    "    list_of_dict_everything.append(new_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(all_together_place, \"w\") as csv_handle:\n",
    "    csv_writer = csv.DictWriter(csv_handle, fieldnames, restval='', extrasaction='ignore')\n",
    "    csv_writer.writeheader()\n",
    "    for result in list_of_dict_everything:\n",
    "        csv_writer.writerow(result)\n",
    "        # print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldnames_for_ml = [\"nad\", \"folinic_acid\", \"coa\", \"nucleo_mix\", \n",
    "                    \"spermidin\", \"pga\", \"aa\", \"trna\", \"mg_gluta\", \"camp\", \"K_gluta\", \n",
    "                     \"yield\", \"yield_std\"]\n",
    "with open(export_place, \"w\") as csv_handle:\n",
    "    csv_writer = csv.DictWriter(csv_handle, fieldnames_for_ml, restval='', extrasaction='ignore')\n",
    "    csv_writer.writeheader()\n",
    "    for result in list_of_dict_ML:\n",
    "        csv_writer.writerow(result)\n",
    "        # print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['row', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23']\n"
     ]
    }
   ],
   "source": [
    "# Draw the plaque - take from the instruction AA script for more ideas.\n",
    "fieldnames_plate = ['row']\n",
    "for i in range(2,24):\n",
    "    fieldnames_plate.append(str(i))\n",
    "print(fieldnames_plate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_info, std_info, ratio_info = {}, {}, {}\n",
    "# \"well_1\", \"well_2\", \"well_3\"\n",
    "for element in list_of_dict_everything:\n",
    "    mean_info[element[\"well_1\"]] = element[\"mean\"]\n",
    "    std_info[element[\"well_1\"]] = element[\"std\"]\n",
    "    ratio_info[element[\"well_1\"]] = float(element[\"std\"])/float(element[\"mean\"]) * 100\n",
    "    mean_info[element[\"well_2\"]] = element[\"mean\"]\n",
    "    std_info[element[\"well_2\"]] = element[\"std\"]\n",
    "    ratio_info[element[\"well_2\"]] = float(element[\"std\"])/float(element[\"mean\"]) * 100\n",
    "    mean_info[element[\"well_3\"]] = element[\"mean\"]\n",
    "    std_info[element[\"well_3\"]] = element[\"std\"]\n",
    "    ratio_info[element[\"well_3\"]] = float(element[\"std\"])/float(element[\"mean\"]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(draw_mean, \"w\") as mean_drawing_file:\n",
    "    writer = csv.DictWriter(mean_drawing_file, fieldnames=fieldnames_plate, restval='0')\n",
    "    writer.writeheader()\n",
    "    current_row = 'A'\n",
    "    row = {}\n",
    "    row[\"row\"] = current_row\n",
    "    for element in sorted(mean_info.keys()):\n",
    "#         print(row)\n",
    "#         print(element)\n",
    "        if element.startswith(current_row):\n",
    "            row[element[1:]] = mean_info[element]\n",
    "        else:\n",
    "            writer.writerow(row)\n",
    "            current_row = element[0]\n",
    "            row = {\"row\": current_row}\n",
    "            row[element[1:]] = mean_info[element]\n",
    "    writer.writerow(row)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(draw_std, \"w\") as std_drawing_file:\n",
    "    writer = csv.DictWriter(std_drawing_file, fieldnames=fieldnames_plate, restval='0')\n",
    "    writer.writeheader()\n",
    "    current_row = 'A'\n",
    "    row = {}\n",
    "    row[\"row\"] = current_row\n",
    "    for element in sorted(std_info.keys()):\n",
    "#         print(row)\n",
    "#         print(element)\n",
    "        if element.startswith(current_row):\n",
    "            row[element[1:]] = std_info[element]\n",
    "        else:\n",
    "            writer.writerow(row)\n",
    "            current_row = element[0]\n",
    "            row = {\"row\": current_row}\n",
    "            row[element[1:]] = std_info[element]\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(draw_ratio, \"w\") as ratio_drawing_file:\n",
    "    writer = csv.DictWriter(ratio_drawing_file, fieldnames=fieldnames_plate, restval='0')\n",
    "    writer.writeheader()\n",
    "    current_row = 'A'\n",
    "    row = {}\n",
    "    row[\"row\"] = current_row\n",
    "    for element in sorted(ratio_info.keys()):\n",
    "#         print(row)\n",
    "#         print(element)\n",
    "        if element.startswith(current_row):\n",
    "            row[element[1:]] = ratio_info[element]\n",
    "        else:\n",
    "            writer.writerow(row)\n",
    "            current_row = element[0]\n",
    "            row = {\"row\": current_row}\n",
    "            row[element[1:]] = ratio_info[element]\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
